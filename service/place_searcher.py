from typing import List, Dict
import re
from playwright.async_api import async_playwright

# ìˆ˜ì§‘ ëŒ€ìƒì¸ ìŒì‹ì  ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸
ACCEPTED_CATEGORIES = [
    # í•œì‹ ê³„ì—´
    "í•œì‹", "ìŒˆë°¥", "ë³´ë¦¬ë°¥", "ë¹„ë¹”ë°¥", "êµ­ë°¥", "ì°Œê°œ,ì „ê³¨", "ê³°íƒ•,ì„¤ë íƒ•", "ê¹€ì¹˜ì°Œê°œ", "ë¶€ëŒ€ì°Œê°œ", "ì²­êµ­ì¥",
    "ì¶”ì–´íƒ•", "ê°ìíƒ•", "í•´ì¥êµ­", "ê°ˆë¹„íƒ•", "ë‘ë¶€ìš”ë¦¬", "ì¹¼êµ­ìˆ˜,ë§Œë‘", "ì „,ë¹ˆëŒ€ë–¡", "ë°±ë°˜,ê°€ì •ì‹", "í•œì‹ë·”í˜", "í•œì •ì‹",
    "êµ­ìˆ˜", "ëƒ‰ë©´", "ë§‰êµ­ìˆ˜", "ì‚¼ê³„íƒ•", "ì£¼ê¾¸ë¯¸ìš”ë¦¬", "ìˆœëŒ€,ìˆœëŒ“êµ­", "ë°±ìˆ™,ì‚¼ê³„íƒ•", "ì¹˜í‚¨,ë‹­ê°•ì •", "ìƒì„ êµ¬ì´",
    # ê³ ê¸° ê³„ì—´
    "ìœ¡ë¥˜,ê³ ê¸°ìš”ë¦¬", "ë‹­ë°œ", "ê³ ê¸°ë·”í˜", "ë¼ì§€ê³ ê¸°êµ¬ì´", "ì¡±ë°œ,ë³´ìŒˆ", "ê³±ì°½,ë§‰ì°½,ì–‘", "ê³ ê¸°ìš”ë¦¬", "ì†Œê³ ê¸°êµ¬ì´", "ë‹­ìš”ë¦¬", "ì‚¼ê²¹ì‚´",
    # ë¶„ì‹ ê³„ì—´
    "ë”¤ì„¬,ì¤‘ì‹ë§Œë‘", "ì¢…í•©ë¶„ì‹", "ê¹€ë°¥", "ë–¡ë³¶ì´", "ë¼ë©´", "ë§Œë‘", "ì£¼ë¨¹ë°¥", "ë¶„ì‹",
    # ì¼ì‹ ê³„ì—´
    "ì¼ì‹ë‹¹", "ëˆê°€ìŠ¤", "ìƒ¤ë¸Œìƒ¤ë¸Œ", "ì˜¤ë‹ˆê¸°ë¦¬", "ì˜¤ë¯€ë¼ì´ìŠ¤", "ì´ˆë°¥,ë¡¤", "ìš°ë™,ì†Œë°”", "ì¼ë³¸ì‹ë¼ë©´",
    "ì¼ì‹íŠ€ê¹€,ê¼¬ì¹˜", "ì¹´ë ˆ", "ì¼ì‹", "ì´ìì¹´ì•¼", "ì°¸ì¹˜íšŒ", "íšŒì „ì´ˆë°¥",
    # ì¤‘ì‹ ê³„ì—´
    "ì¤‘ì‹ë‹¹", "ì–‘ê¼¬ì¹˜", "ë§ˆë¼íƒ•", "ê²Œìš”ë¦¬", "ë”¤ì„¬", "ì¤‘ì‹", "ì¤‘í™”ìš”ë¦¬",
    # ì–‘ì‹ ê³„ì—´
    "ë¸ŒëŸ°ì¹˜", "ìŠ¤í…Œì´í¬,ë¦½", "í”¼ì", "íŒŒìŠ¤íƒ€", "íŒ¨ë°€ë¦¬ë ˆìŠ¤í† ë‘",
    "ê²½ì–‘ì‹", "ìŠ¤íŒŒê²Œí‹°", "ë¸ŒëŸ°ì¹˜ì¹´í˜", "ì–‘ì‹", "ë…ì¼ìŒì‹", "ìŠ¤íŒŒê²Œí‹°,íŒŒìŠ¤íƒ€ì „ë¬¸",
    # ì„¸ê³„ ìŒì‹
    "ì´íƒˆë¦¬ì•„ìŒì‹", "ìŠ¤í˜ì¸ìŒì‹", "í”„ë‘ìŠ¤ìŒì‹", "í„°í‚¤ìŒì‹", "ì•„í”„ë¦¬ì¹´ìŒì‹",
    "ë©•ì‹œì½”,ë‚¨ë¯¸ìŒì‹", "ë² íŠ¸ë‚¨ìŒì‹", "íƒœêµ­ìŒì‹", "ì¸ë„ìŒì‹", "ì•„ì‹œì•„ìŒì‹",
    "ë©•ì‹œì¹¸,ë¸Œë¼ì§ˆ", "í“¨ì „ìŒì‹",
    # ì£¼ì 
    "ìš”ë¦¬ì£¼ì ", "ìˆ ì§‘", "í¬ì¥ë§ˆì°¨", "ë°”(BAR)", "ì™€ì¸ë°”", "ì™€ì¸", "ë§¥ì£¼,í˜¸í”„", "ì¹µí…Œì¼ë°”", "ì´ìì¹´ì•¼",
    # ê·¸ ì™¸ ìŒì‹ì 
    "í‘¸ë“œíŠ¸ëŸ­", "í‘¸ë“œì½”íŠ¸", "í† ìŠ¤íŠ¸", "í–„ë²„ê±°", "ì£½", "ë„ì‹œë½", "ìƒëŸ¬ë“œ", "ìƒŒë“œìœ„ì¹˜", "í•«ë„ê·¸", "í›„ë Œì¹˜í›„ë¼ì´",
    "ë‹¤ì´ì–´íŠ¸,ìƒëŸ¬ë“œ", "ì±„ì‹,ìƒëŸ¬ë“œë·”í˜", "ë®ë°¥", "ì² íŒìš”ë¦¬", "ì¹˜í‚¨", "íŒ¨ìŠ¤íŠ¸í‘¸ë“œ",
    "ì•¼ì‹", "ì‚¬ì² ,ì˜ì–‘íƒ•", "ì‚¬ì°°ìŒì‹", "ê¸°ì‚¬ì‹ë‹¹", "í–¥í† ìŒì‹", "ì´ë¶ìŒì‹", "ë ˆìŠ¤í† ë‘",
    "í•´ë¬¼,ìƒì„ ìš”ë¦¬", "ì¼ì‹,ì´ˆë°¥ë·”í˜", "í•´ì‚°ë¬¼ë·”í˜", "ìƒì„ íšŒ", "ë„ì‹œë½,ì»µë°¥", "ì°œë‹­", "ì¡°ê°œìš”ë¦¬", "ì˜¤ë¦¬ìš”ë¦¬", "ì•„ê·€ì°œ,í•´ë¬¼ì°œ", "ë°”ë‹·ê°€ì¬ìš”ë¦¬"
]

MIN_REVIEW_COUNT = 140  # ë°©ë¬¸ì ë¦¬ë·° ì•ˆì •ì„ 
MIN_RATING = 4.1        # ìµœì†Œ ë³„ì  ê¸°ì¤€

# ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ í•¨ìˆ˜
async def fetch_places(district: str, max_places: int) -> List[Dict]:
    # íŠ¹ì • ì§€ì—­ì—ì„œ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¥ì†Œ ìµœëŒ€ max_placesê°œê¹Œì§€ ìˆ˜
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context()
        page = await context.new_page()
        
        search_word = district + " ë§›ì§‘"
        search_url = f"https://map.naver.com/p/search/{search_word}"
        
        await page.goto(search_url)
        await page.wait_for_timeout(1500) # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°

        results = []
        current_page = 1
        MAX_PAGES = 5

        while current_page <= MAX_PAGES and len(results) < max_places:
            try:
                print(f"\n=== {current_page}í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘ ===")
                
                iframe_element = await page.wait_for_selector("iframe#searchIframe", timeout=5000)
                if not iframe_element:
                    print("âŒ iframe_element í”„ë ˆì„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    break
                
                search_frame = await iframe_element.content_frame()
                if not search_frame:
                    print("âŒ searchIframe í”„ë ˆì„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    break

                scroll_container = await search_frame.wait_for_selector("div#_pcmap_list_scroll_container", timeout=10000)
                if not scroll_container:
                    print("âŒ scroll containerë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    break

                # ìŠ¤í¬ë¡¤ ë‹¤ìš´ìœ¼ë¡œ ì „ì²´ ì•„ì´í…œ ë¡œë”© ìœ ë„
                previous_height = 0
                while True:
                    current_height = await scroll_container.evaluate("(el) => el.scrollHeight")
                    await scroll_container.evaluate("(el) => el.scrollTo(0, el.scrollHeight)")
                    await page.wait_for_timeout(700)

                    if current_height == previous_height:
                        break
                    previous_height = current_height

                items = await search_frame.query_selector_all("li.UEzoS.rTjJo")
                print(f"âœ… {current_page}í˜ì´ì§€ì—ì„œ {len(items)}ê°œ ì¥ì†Œ ë°œê²¬")

                # ê° itemsì—ì„œ ì¥ì†Œ ì–»ê¸°
                await parse_places_from_items(items, page, max_places, results)

                # ë‹¤ìŒ í˜ì´ì§€ ë„˜ê¸°ê¸°
                next_page_buttons = await search_frame.query_selector_all("a.eUTV2")
                next_btn = None

                for btn in next_page_buttons:
                    span = await btn.query_selector("span.place_blind")
                    if span:
                        text = await span.inner_text()
                        if "ë‹¤ìŒí˜ì´ì§€" in text:
                            next_btn = btn
                            break

                if next_btn:
                    is_disabled = await next_btn.get_attribute("aria-disabled")
                    if is_disabled == "false":
                        print("â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...")
                        await next_btn.click()
                        await page.wait_for_timeout(1500)
                        current_page += 1
                    else:
                        print("â›” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë¨. ì¢…ë£Œ")
                        break
                else:
                    print("âŒ ë‹¤ìŒí˜ì´ì§€ ë²„íŠ¼ ëª» ì°¾ìŒ. ì¢…ë£Œ")
                    break

            except Exception as e:
                print(f"[ERROR] í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                break

        await browser.close()
        return results

async def parse_places_from_items(items, page, max_places: int, results: List[Dict]) -> None:
    for item in items:
        if len(results) >= max_places:
            break

        try:
            # ì¥ì†Œ ì´ë¦„
            place_name_el = await item.query_selector("span.TYaxT")
            place_name = await place_name_el.text_content() if place_name_el else "N/A"

            # ì¹´í…Œê³ ë¦¬
            category_el = await item.query_selector("span.KCMnt")
            category = await category_el.text_content() if category_el else "N/A"
            if category not in ACCEPTED_CATEGORIES:
                print(f"ğŸš« ì¹´í…Œê³ ë¦¬ ì œì™¸: {category}")
                continue

            # ë°©ë¬¸ì ë¦¬ë·°
            review_el = await item.query_selector_all("span.h69bs")
            review_count = 0
            for span in review_el:
                text = await span.inner_text()
                if "ë¦¬ë·°" in text:
                    digits = re.search(r"(\d+)", text)
                    if digits:
                        review_count = int(digits.group(1))
                    break
            if review_count < MIN_REVIEW_COUNT:
                print(f"ğŸš« ë¦¬ë·° ìˆ˜ ë¶€ì¡±: {review_count}")
                continue

            # ë³„ì 
            rating = None
            rating_el = await item.query_selector("span.h69bs.orXYY")
            rating_text = await rating_el.text_content() if rating_el else None
            if rating_text:
                match_rating = re.search(r"[\d.]+", rating_text)
                rating = float(match_rating.group()) if match_rating else 0.0
                if rating < MIN_RATING:
                    print(f"ğŸš« ë³„ì  ë‚®ìŒ: {rating}")
                    continue

            # ìƒì„¸ í˜ì´ì§€ ì´ë™ í›„ ID ì¶”ì¶œ
            click_target = await item.query_selector("div.place_bluelink")
            if click_target:
                await click_target.click()
                await page.wait_for_timeout(1500)
                detail_url = page.url
                match = re.search(r'/place/(\d+)', detail_url)
                if match:
                    place_id = match.group(1)
                    print(f"âœ… {len(results) + 1}ë²ˆì§¸ ì¥ì†Œ ID: {place_id}")
                    results.append({
                        "id": place_id,
                        "name": place_name,
                        "category": category,
                        "review_count": review_count,
                        "rating": rating,
                    })
                else:
                    print("âŒ place_id ì¶”ì¶œ ì‹¤íŒ¨")

        except Exception as e:
            print(f"[ERROR] í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
