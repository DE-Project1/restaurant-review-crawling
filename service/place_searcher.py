from typing import List
import re
from playwright.async_api import async_playwright
from service.utils import block_unnecessary_resources, scroll_until_no_more

# ìˆ˜ì§‘ ëŒ€ìƒì¸ ìŒì‹ì  ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸
ACCEPTED_CATEGORIES = [
    # í•œì‹ ê³„ì—´
    "í•œì‹", "ìŒˆë°¥", "ë³´ë¦¬ë°¥", "ë¹„ë¹”ë°¥", "êµ­ë°¥", "ì°Œê°œ,ì „ê³¨", "ê³°íƒ•,ì„¤ë íƒ•", "ê¹€ì¹˜ì°Œê°œ", "ë¶€ëŒ€ì°Œê°œ", "ì²­êµ­ì¥",
    "ì¶”ì–´íƒ•", "ê°ìíƒ•", "í•´ì¥êµ­", "ê°ˆë¹„íƒ•", "ë‘ë¶€ìš”ë¦¬", "ì¹¼êµ­ìˆ˜,ë§Œë‘", "ì „,ë¹ˆëŒ€ë–¡", "ë°±ë°˜,ê°€ì •ì‹", "í•œì‹ë·”í˜", "í•œì •ì‹",
    "êµ­ìˆ˜", "ëƒ‰ë©´", "ë§‰êµ­ìˆ˜", "ì‚¼ê³„íƒ•", "ì£¼ê¾¸ë¯¸ìš”ë¦¬", "ìˆœëŒ€,ìˆœëŒ“êµ­", "ë°±ìˆ™,ì‚¼ê³„íƒ•", "ì¹˜í‚¨,ë‹­ê°•ì •", "ìƒì„ êµ¬ì´",
    # ê³ ê¸° ê³„ì—´
    "ìœ¡ë¥˜,ê³ ê¸°ìš”ë¦¬", "ë‹­ë°œ", "ê³ ê¸°ë·”í˜", "ë¼ì§€ê³ ê¸°êµ¬ì´", "ì¡±ë°œ,ë³´ìŒˆ", "ê³±ì°½,ë§‰ì°½,ì–‘", "ê³ ê¸°ìš”ë¦¬", "ì†Œê³ ê¸°êµ¬ì´", "ë‹­ìš”ë¦¬", "ì‚¼ê²¹ì‚´",
    # ë¶„ì‹ ê³„ì—´
    "ë”¤ì„¬,ì¤‘ì‹ë§Œë‘", "ì¢…í•©ë¶„ì‹", "ê¹€ë°¥", "ë–¡ë³¶ì´", "ë¼ë©´", "ë§Œë‘", "ì£¼ë¨¹ë°¥", "ë¶„ì‹",
    # ì¼ì‹ ê³„ì—´
    "ì¼ì‹ë‹¹", "ëˆê°€ìŠ¤", "ìƒ¤ë¸Œìƒ¤ë¸Œ", "ì˜¤ë‹ˆê¸°ë¦¬", "ì˜¤ë¯€ë¼ì´ìŠ¤", "ì´ˆë°¥,ë¡¤", "ìš°ë™,ì†Œë°”", "ì¼ë³¸ì‹ë¼ë©´",
    "ì¼ì‹íŠ€ê¹€,ê¼¬ì¹˜", "ì¹´ë ˆ", "ì¼ì‹", "ì´ìì¹´ì•¼", "ì°¸ì¹˜íšŒ", "íšŒì „ì´ˆë°¥",
    # ì¤‘ì‹ ê³„ì—´
    "ì¤‘ì‹ë‹¹", "ì–‘ê¼¬ì¹˜", "ë§ˆë¼íƒ•", "ê²Œìš”ë¦¬", "ë”¤ì„¬", "ì¤‘ì‹", "ì¤‘í™”ìš”ë¦¬",
    # ì–‘ì‹ ê³„ì—´
    "ë¸ŒëŸ°ì¹˜", "ìŠ¤í…Œì´í¬,ë¦½", "í”¼ì", "íŒŒìŠ¤íƒ€", "íŒ¨ë°€ë¦¬ë ˆìŠ¤í† ë‘",
    "ê²½ì–‘ì‹", "ìŠ¤íŒŒê²Œí‹°", "ë¸ŒëŸ°ì¹˜ì¹´í˜", "ì–‘ì‹", "ë…ì¼ìŒì‹", "ìŠ¤íŒŒê²Œí‹°,íŒŒìŠ¤íƒ€ì „ë¬¸",
    # ì„¸ê³„ ìŒì‹
    "ì´íƒˆë¦¬ì•„ìŒì‹", "ìŠ¤í˜ì¸ìŒì‹", "í”„ë‘ìŠ¤ìŒì‹", "í„°í‚¤ìŒì‹", "ì•„í”„ë¦¬ì¹´ìŒì‹",
    "ë©•ì‹œì½”,ë‚¨ë¯¸ìŒì‹", "ë² íŠ¸ë‚¨ìŒì‹", "íƒœêµ­ìŒì‹", "ì¸ë„ìŒì‹", "ì•„ì‹œì•„ìŒì‹",
    "ë©•ì‹œì¹¸,ë¸Œë¼ì§ˆ", "í“¨ì „ìŒì‹",
    # ì£¼ì 
    "ìš”ë¦¬ì£¼ì ", "ìˆ ì§‘", "í¬ì¥ë§ˆì°¨", "ë°”(BAR)", "ì™€ì¸ë°”", "ì™€ì¸", "ë§¥ì£¼,í˜¸í”„", "ì¹µí…Œì¼ë°”", "ì´ìì¹´ì•¼",
    # ê·¸ ì™¸ ìŒì‹ì 
    "í‘¸ë“œíŠ¸ëŸ­", "í‘¸ë“œì½”íŠ¸", "í† ìŠ¤íŠ¸", "í–„ë²„ê±°", "ì£½", "ë„ì‹œë½", "ìƒëŸ¬ë“œ", "ìƒŒë“œìœ„ì¹˜", "í•«ë„ê·¸", "í›„ë Œì¹˜í›„ë¼ì´",
    "ë‹¤ì´ì–´íŠ¸,ìƒëŸ¬ë“œ", "ì±„ì‹,ìƒëŸ¬ë“œë·”í˜", "ë®ë°¥", "ì² íŒìš”ë¦¬", "ì¹˜í‚¨", "íŒ¨ìŠ¤íŠ¸í‘¸ë“œ",
    "ì•¼ì‹", "ì‚¬ì² ,ì˜ì–‘íƒ•", "ì‚¬ì°°ìŒì‹", "ê¸°ì‚¬ì‹ë‹¹", "í–¥í† ìŒì‹", "ì´ë¶ìŒì‹", "ë ˆìŠ¤í† ë‘",
    "í•´ë¬¼,ìƒì„ ìš”ë¦¬", "ì¼ì‹,ì´ˆë°¥ë·”í˜", "í•´ì‚°ë¬¼ë·”í˜", "ìƒì„ íšŒ", "ë„ì‹œë½,ì»µë°¥", "ì°œë‹­", "ì¡°ê°œìš”ë¦¬", "ì˜¤ë¦¬ìš”ë¦¬", "ì•„ê·€ì°œ,í•´ë¬¼ì°œ", "ë°”ë‹·ê°€ì¬ìš”ë¦¬"
]

MIN_REVIEW_COUNT = 140  # ë°©ë¬¸ì ë¦¬ë·°
MIN_RATING = 4.1        # ìµœì†Œ ë³„ì  ê¸°ì¤€

# ì¥ì†Œ ê²€ìƒ‰ ë° ID ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ í•¨ìˆ˜
# íŠ¹ì • ì§€ì—­ì—ì„œ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¥ì†Œ ìµœëŒ€ max_placesê°œê¹Œì§€ ìˆ˜ì§‘ (place_idë§Œ)
async def search_and_fetch_place_ids(district: str, max_places: int) -> List[str]:
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False, args=["--window-size=400,800"])
        context = await browser.new_context(
            viewport={"width": 400, "height": 800},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
        )
        page = await context.new_page()
        await block_unnecessary_resources(page)
        # í˜ì´ì§€ ì´ë™
        search_word = district + " ë§›ì§‘"
        await page.goto(f"https://map.naver.com/p/search/{search_word}")
        await page.wait_for_timeout(2000)  # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
        # place_idsì— ì¥ì†Œ ID ìˆ˜ì§‘
        place_ids = []
        current_page = 1
        while current_page <= 5 and len(place_ids) < max_places: # ìµœëŒ€ í˜ì´ì§€ ë²ˆí˜¸ 5; ì¥ì†Œ ìˆ˜ max_places ì´í•˜ì—¬ì•¼
            try:
                print(f"\n=== {current_page}í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘ ===")
                iframe_element = await page.wait_for_selector("iframe#searchIframe", timeout=5000)
                search_frame = await iframe_element.content_frame()
                scroll_container = await search_frame.wait_for_selector("div#_pcmap_list_scroll_container", timeout=10000)
                await scroll_until_no_more(scroll_container) # ìŠ¤í¬ë¡¤ ë‹¤ìš´ìœ¼ë¡œ ì „ì²´ ì•„ì´í…œ ë¡œë”©
                place_items = await search_frame.query_selector_all("li.UEzoS.rTjJo")
                print(f"âœ… {current_page}í˜ì´ì§€ì—ì„œ {len(place_items)}ê°œ ì¥ì†Œ ë°œê²¬")
                # place_itemsì—ì„œ ì¥ì†Œ new_ids ì–»ì–´ place_idsì— ì¶”ê°€
                new_ids = await parse_places_from_items(place_items, page, max_places)
                place_ids.extend(new_ids)
                if len(place_ids) >= max_places:
                    break
                # ë‹¤ìŒ í˜ì´ì§€ ë„˜ê¸°ê¸°
                next_btn = search_frame.locator('a.eUTV2:has(span.place_blind:text("ë‹¤ìŒí˜ì´ì§€"))').first
                if await next_btn.count() == 0:
                    print("âŒ ë‹¤ìŒí˜ì´ì§€ ë²„íŠ¼ ëª» ì°¾ìŒ. ì¢…ë£Œ")
                    return False
                # ë¹„í™œì„±í™” ìƒíƒœì¸ì§€ í™•ì¸
                if await next_btn.get_attribute("aria-disabled") == "true":
                    print("â›” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë¨. ì¢…ë£Œ")
                    return False
                # í´ë¦­ í›„ ëŒ€ê¸°
                current_page += 1
                await next_btn.click()
                await page.wait_for_timeout(1500)
            except Exception as e:
                print(f"[ERROR] í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                break
        await context.close()
        await browser.close()
        return place_ids

async def parse_places_from_items(items, page, max_places: int) -> List[str] :
    place_ids: List[str] = []
    for item in items:
        if len(place_ids) >= max_places:
            break
        try:
            # ì¹´í…Œê³ ë¦¬
            category_el = await item.query_selector("span.KCMnt")
            category = await category_el.text_content() if category_el else "N/A"
            if category not in ACCEPTED_CATEGORIES:
                print(f"ğŸš« ì¹´í…Œê³ ë¦¬ ì œì™¸: {category}")
                continue
            # ë°©ë¬¸ì ë¦¬ë·°
            review_el = await item.query_selector_all("span.h69bs")
            review_count = 0
            for span in review_el:
                text = await span.inner_text()
                if "ë¦¬ë·°" in text:
                    digits = re.search(r"(\d+)", text)
                    if digits:
                        review_count = int(digits.group(1))
                    break
            if review_count < MIN_REVIEW_COUNT:
                print(f"ğŸš« ë¦¬ë·° ìˆ˜ ë¶€ì¡±: {review_count}")
                continue
            # ë³„ì 
            rating_el = await item.query_selector("span.h69bs.orXYY")
            rating_text = await rating_el.text_content() if rating_el else None
            if rating_text:
                match_rating = re.search(r"[\d.]+", rating_text)
                rating = float(match_rating.group()) if match_rating else 0.0
                if rating < MIN_RATING:
                    print(f"ğŸš« ë³„ì  ë‚®ìŒ: {rating}")
                    continue
            # ìƒì„¸ í˜ì´ì§€ ì´ë™ í›„ ID ì¶”ì¶œ
            click_target = await item.query_selector("div.place_bluelink")
            if click_target:
                await click_target.click()
                await page.wait_for_timeout(1500)
                detail_url = page.url
                match = re.search(r'/place/(\d+)', detail_url)
                if match:
                    place_id = match.group(1)
                    print(f"âœ… {len(place_ids) + 1}ë²ˆì§¸ ì¥ì†Œ ID: {place_id}")
                    place_ids.append(place_id)
                else:
                    print("âŒ place_id ì¶”ì¶œ ì‹¤íŒ¨")
        except Exception as e:
            print(f"[ERROR] í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
    return place_ids