import os
import csv
import time
import glob
import asyncio
from crawl_place_info_html import crawl_from_place_ids

RAW_DIR = "raw_data"
PLACE_CSV_DIR = "data/place_info"
ADM_DONG_CODES = ["1111", "1114", "1120"]

from itertools import chain

async def crawl_missing_place_ids():
    os.makedirs(RAW_DIR, exist_ok=True)

    csv_files = list(chain.from_iterable(
        glob.glob(f"{PLACE_CSV_DIR}/place_info_{dong_code}*.csv") for dong_code in ADM_DONG_CODES
    ))

    for csv_path in csv_files:
        global_start = time.time()
        adm_dong_code = os.path.splitext(os.path.basename(csv_path))[0].split("_")[-1]

        place_ids_to_crawl = set()

        # ìˆ˜ì§‘í•´ì•¼ í•  place_id ì°¾ê¸°
        with open(csv_path, newline='', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                place_id = row.get("place_id")
                if not place_id:
                    continue
                output_path = f"{RAW_DIR}/adc_{adm_dong_code}_place_rawdata_{place_id}.txt"
                if os.path.exists(output_path):
                    continue  # ì´ë¯¸ ìˆìœ¼ë©´ skip
                place_ids_to_crawl.add(place_id)

        if not place_ids_to_crawl:
            print(f"âœ… {adm_dong_code}: ëª¨ë‘ ìˆ˜ì§‘ë¨ (skip)")
            continue

        print(f"ğŸš€ {adm_dong_code}: {len(place_ids_to_crawl)}ê°œ ìˆ˜ì§‘ ì‹œì‘")

        # í¬ë¡¤ë§ ì‹¤í–‰
        try:
            results = await crawl_from_place_ids(list(place_ids_to_crawl))
        except Exception as e:
            print(f"âŒ [ERROR] í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
            continue

        saved_count = 0
        for data in results:
            if data is None:
                continue  # ì‹¤íŒ¨í–ˆê±°ë‚˜ skipëœ ë°ì´í„°

            place_id = data["place_id"]
            output_path = f"{RAW_DIR}/adc_{adm_dong_code}_place_rawdata_{place_id}.txt"

            if os.path.exists(output_path):
                continue  # ì¤‘ë³µ ì €ì¥ ë°©ì§€

            try:
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write("===== HOME =====\n")
                    f.write(data["home_html"] or "")
                    f.write("\n\n===== INFO =====\n")
                    f.write(data["info_html"] or "")
                    f.write("\n\n===== REVIEWS =====\n")
                    f.write(data["reviews_html"] or "")
                saved_count += 1
            except Exception as e:
                print(f"âš ï¸ ì €ì¥ ì‹¤íŒ¨ (PlaceID: {place_id}) - {e}")

        global_elapsed = time.time() - global_start
        print(f"âœ… {adm_dong_code}: ì €ì¥ ì™„ë£Œ ({saved_count}ê°œ ì €ì¥ë¨ / {len(results)}ê°œ í¬ë¡¤ë§ë¨) - ì „ì²´ ì†Œìš”ì‹œê°„: {global_elapsed:.1f} sec\n")


if __name__ == "__main__":
    asyncio.run(crawl_missing_place_ids())
