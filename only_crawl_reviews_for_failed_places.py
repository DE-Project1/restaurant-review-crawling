import csv
import asyncio
from playwright.async_api import async_playwright
from service.place_data_collector import crawl_reviews
from storage.save_data import save_reviews_csv

INPUT_PATH = "data/failed_places.csv"
OUTPUT_PATH = "data/failed_places.csv"  # ê°™ì€ ê²½ë¡œì— ë®ì–´ì“°ê¸°

async def only_review_crawling_batch(input_path):
    # CSV íŒŒì¼ ë¡œë“œ
    with open(input_path, newline='', encoding='utf-8-sig') as csvfile:
        reader = csv.DictReader(csvfile)
        rows = list(reader)  # ì „ì²´ row ì €ì¥
        targets = [
            (row['adm_dong_code'], row['pname'], row['pid'], row)
            for row in rows if row.get('adm_dong_code') and row.get('pname') and row.get('pid')
        ]

    succeeded_pids = set()

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
        )

        for adm_dong_code, pname, pid, row in targets:
            page = await context.new_page()
            try:
                print(f"ğŸ” ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘: {pname} ({pid})")
                reviews = await asyncio.wait_for(
                    crawl_reviews(page, pid, pname),
                    timeout=120
                )
                if reviews:
                    save_reviews_csv(reviews, adm_dong_code)
                    succeeded_pids.add(pid)
                    print(f"âœ… ë¦¬ë·° ì €ì¥ ì™„ë£Œ: {pname} | ë¦¬ë·° ìˆ˜: {len(reviews)}")
                else:
                    print(f"âš ï¸ ë¦¬ë·° ì—†ìŒ: {pname}")
            except asyncio.TimeoutError:
                print(f"[ERROR] Timeout - {pname} ({pid})")
            except Exception as e:
                print(f"[ERROR] ì˜ˆì™¸ ë°œìƒ - {pname} ({pid}): {e}")
            finally:
                await page.close()

        await browser.close()

    # ì‹¤íŒ¨í•œ rowë§Œ ë‹¤ì‹œ ì €ì¥
    failed_rows = [row for _, _, pid, row in targets if pid not in succeeded_pids]
    if failed_rows:
        fieldnames = failed_rows[0].keys()
        with open(OUTPUT_PATH, "w", newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(failed_rows)
        print(f"ì‹¤íŒ¨í•œ {len(failed_rows)}ê°œ í•­ëª©ì„ {OUTPUT_PATH}ì— ì €ì¥ ì™„ë£Œ")
    else:
        print("ëª¨ë“  ì‹¤íŒ¨í•œ ì¥ì†Œ ë¦¬ë·° ìˆ˜ì§‘ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(only_review_crawling_batch(INPUT_PATH))
